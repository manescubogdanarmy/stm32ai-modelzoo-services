general:
  project_name: segmentation
  model_type : deeplab_v3
  saved_models_dir: saved_models
  gpu_memory_limit: 12
  global_seed: 127
  display_figures: False

operation_mode: chain_tqeb

dataset:
  name: pascal_voc
  class_names: ["background", "aeroplane", "bicycle", "bird", "boat", "bottle", "bus",
                "car", "cat", "chair", "cow", "dining table", "dog", "horse", "motorbike",
                "person", "potted plant", "sheep", "sofa", "train", "tv/monitor"]

  training_path: ./datasets/VOC2012_train_val/JPEGImages
  training_masks_path: ./datasets/VOC2012_train_val/SegmentationClassAug
  training_files_path: ./datasets/VOC2012_train_val/test_nano_full.txt  #../datasets/VOC2012_train_val/ImageSets/Segmentation/trainaug.txt

  validation_path: ./datasets/VOC2012_train_val/JPEGImages
  validation_masks_path: ./datasets/VOC2012_train_val/SegmentationClassAug
  validation_files_path: ./datasets/VOC2012_train_val/test_nano_full.txt  #../datasets/VOC2012_train_val/ImageSets/Segmentation/val.txt
  validation_split: 
  
preprocessing:
  rescaling: {scale: 1/127.5, offset: -1}
  resizing:
    aspect_ratio: fit
    interpolation: bilinear 
  color_mode: rgb

data_augmentation:
  random_flip:
    mode: horizontal_and_vertical
  random_crop:
    crop_center_x: (0.25, 0.75)
    crop_center_y: (0.25, 0.75)
    crop_width: (0.6, 0.9)
    crop_height: (0.6, 0.9)
    change_rate: 0.6
  random_contrast:
    factor: 0.4
  random_brightness:
    factor: 0.3

training:
  model: 
    name: mobilenet
    version: v2 
    alpha: 0.5
    aspp: v2
    output_stride: 16  # the only supported for now 
    input_shape: (512, 512, 3)
    pretrained_weights: null
  dropout: 0.6
  batch_size: 16
  epochs: 1
  optimizer:
    Adam:
      learning_rate: 0.005
  callbacks:          
    ReduceLROnPlateau:
      monitor: val_accuracy
      mode: max
      factor: 0.5
      patience: 40
      min_lr: 1.0e-05
    EarlyStopping:
      monitor: val_accuracy
      mode: max
      restore_best_weights: true
      patience: 60
      
quantization:
   quantizer: TFlite_converter
   quantization_type: PTQ
   quantization_input_type: uint8
   quantization_output_type: float
   export_dir: quantized_models

tools:
   stedgeai:
      version: 10.2.0
      optimization: balanced
      on_cloud: True
      path_to_stedgeai: C:/ST/STEdgeAI/<x.y>/Utilities/windows/stedgeai.exe
   path_to_cubeIDE: C:/ST/STM32CubeIDE_<*.*.*>/STM32CubeIDE/stm32cubeide.exe

benchmarking:
   board: STM32MP257F-EV1
   
mlflow:
  uri: ./src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}