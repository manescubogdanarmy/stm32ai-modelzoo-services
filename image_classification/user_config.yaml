general:
  project_name: sensor_classification_v2
  model_path:
  logs_dir: logs
  saved_models_dir: saved_models
  display_figures: True
  global_seed: 456  # Different seed for new training
  gpu_memory_limit: 8

operation_mode: training

dataset:
  name: sensor_data
  class_names: ['high_body_temperature', 'muscle_fatigue', 'emg_fatigue', 'poor_posture', 'high_env_temperature', 'high_stress', 'eye_fatigue', 'normal']
  training_path: ./datasets/sensor_data  # Mandatory
  validation_path:        # Optional
  validation_split: 0.25   # Larger validation set to better detect overfitting
  test_path:              # Optional
  quantization_path:      # Optional
  quantization_split:     # Optional
  check_image_files: True  # Optional, set it to True if you want to check that all the image files can be read successfully
  seed: 456               # Match global seed

preprocessing:
  rescaling:
    scale: 1/255.0
    offset: 0
  resizing:
    interpolation: nearest
    aspect_ratio: fit
  color_mode: grayscale

data_augmentation:    # Enable light augmentation to improve generalization
  random_flip:
    mode: horizontal  # Horizontal flip may help generalization
  random_translation:
    width_factor: 0.05  # Very small translation to preserve sensor patterns
    height_factor: 0.0  # No vertical translation for 2-pixel height
    fill_mode: constant
    interpolation: nearest

training:
  model:    # Use it if you want to use a model from the zoo, mutually exclusive with 'general.model_path'
    name: stmnist  # Using a simpler model for small sensor data
    input_shape: (32, 32, 1)  # Resize 16x2 to 32x32 greyscale for better compatibility
  resume_training_from: # Optional, use to resume a training from a previous experiment.
                        # Example: experiments_outputs/2023_10_26_18_36_09/saved_models/last_augmented_model.h5 
  frozen_layers: None  #(0:-1)            # Optional, use if you want to freeze some layers (by default all layers are trainable)
  dropout: 0.3                     # Reduced dropout for better learning
  batch_size: 16                   # Smaller batch size for more stable training
  epochs: 50                       # Fewer epochs to prevent overfitting
  optimizer:
    Adam:
      learning_rate: 0.0001         # Lower learning rate for more stable training
  callbacks:          # More aggressive early stopping
    ReduceLROnPlateau:
      monitor: val_loss             # Monitor validation loss instead of accuracy
      mode: min
      factor: 0.5
      patience: 5                   # Reduce patience
      min_lr: 1.0e-06
    EarlyStopping:
      monitor: val_loss             # Monitor validation loss for better generalization
      mode: min
      restore_best_weights: true
      patience: 10                  # Reduced patience to prevent overfitting
#  trained_model_path: trained.h5   # Optional, use it if you want to save the best model at the end of the training to a path of your choice

quantization:
  quantizer: TFlite_converter
  quantization_type: PTQ
  quantization_input_type: uint8
  quantization_output_type: float
  granularity: per_channel   #per_tensor
  optimize: False   #can be True if per_tensor
  export_dir: quantized_models

# The prediction section is optional unless you set operation_mode to "prediction".
# If you do so, the attribute test_files_path is mandatory.
prediction:
  test_files_path: ./datasets/flower_photos/daisy

tools:
  stedgeai:
    version: 10.0.0
    optimization: balanced
    on_cloud: True
    path_to_stedgeai: C:/Users/<XXXXX>/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/<*.*.*>/Utilities/windows/stedgeai.exe
  path_to_cubeIDE: C:/ST/STM32CubeIDE_<*.*.*>/STM32CubeIDE/stm32cubeide.exe

benchmarking:
  board: STM32H747I-DISCO

deployment:
  c_project_path: ../application_code/image_classification/STM32N6
  IDE: GCC
  verbosity: 1
  hardware_setup:
    serie: STM32H7
    board: STM32H747I-DISCO
    input: CAMERA_INTERFACE_DCMI
    output: DISPLAY_INTERFACE_USB

mlflow:
  uri: ./src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}
