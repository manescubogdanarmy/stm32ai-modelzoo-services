{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNkqsp45yZBp"
      },
      "source": [
        "<h1>Training and Benchmarking a Model Using Model Zoo</h1>\n",
        "\n",
        "This notebook provides a step-by-step guide on how to use the **STM32AI model zoo** to train, quantize, and benchmark an image classification model. The resulting model can be deployed on STM32 targets, making it ideal for edge computing applications. This notebook can be used in Jupyter Notebook environments, __(in local installation setup or in Google Colab)__ providing flexibility for users who prefer different development environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S169jHOt3qLY"
      },
      "source": [
        "## License of the Jupyter Notebook\n",
        "\n",
        "This software component is licensed by ST under BSD-3-Clause license, \n",
        "the \"License\";\n",
        "\n",
        "You may not use this file except in compliance with the\n",
        "License.\n",
        "\n",
        "You may obtain a copy of the License at: https://opensource.org/licenses/BSD-3-Clause\n",
        "\n",
        "Copyright (c) 2023 STMicroelectronics. All rights reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyAK7KjSix-T"
      },
      "source": [
        "<div style=\"border-bottom: 3px solid #273B5F\">\n",
        "<h2>Table of content</h2>\n",
        "<ul style=\"list-style-type: none\">\n",
        "<li><a href=\"#install\">1. Install necessary packages</a>\n",
        "<li><a href=\"#config\">2. Configure environment variables to access STM32Cube.AI Developer Cloud Services</a></li>\n",
        "<li><a href=\"#upload\">3. Upload the dataset</h2> </a></li>\n",
        "<li><a href=\"#training\">4. Training and Benchmarking the Model</a></li>\n",
        "<li><a href=\"#results\">5. Results</a></li>\n",
        "  </ul>\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbNXaOtk3qLY"
      },
      "source": [
        "<div id=\"install\">\n",
        "    <h2>1. Install necessary packages</h2>\n",
        "</div>\n",
        "\n",
        "To get started, upload the model zoo package and clone the repository using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbj1tvrV2qC-"
      },
      "outputs": [],
      "source": [
        "# verifying if running in google colab\n",
        "import sys\n",
        "import os\n",
        "if 'google.colab' in sys.modules:\n",
        "  os.environ[\"GOOGLE_COLAB\"]=\"1\"\n",
        "  print(\"Running the Notebook in Google Colab!\")\n",
        "else:\n",
        "  os.environ[\"GOOGLE_COLAB\"]=\"0\"\n",
        "  print(\"Running the Notebook local Jupyter Server!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If running on Google Colab setting up the Python requirements for running modelzoo with `Python 3.10.x`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MPK3olxc0n3",
        "outputId": "e6e12dc1-f489-46d7-9088-9a47d9cf6e6a"
      },
      "outputs": [],
      "source": [
        "if os.environ[\"GOOGLE_COLAB\"]==\"1\":\n",
        "  !apt install python3.10 python3.10-distutils\n",
        "  !curl -sS https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "\n",
        "  !python3.10 get-pip.py\n",
        "  !python3.10 -m pip --version\n",
        "\n",
        "  !apt install python3.10-venv\n",
        "\n",
        "  !python3.10 -m pip install nvidia-cuda-runtime-cu11==11.8.89\n",
        "  !python3.10 -m pip install nvidia-cudnn-cu11\n",
        "\n",
        "  !wget https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda_11.2.0_460.27.04_linux.run\n",
        "  !chmod +x cuda_11.2.0_460.27.04_linux.run\n",
        "  !./cuda_11.2.0_460.27.04_linux.run --override --silent --toolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUe7gfVE5QgV"
      },
      "source": [
        "## (Optional to profit from GPU on Google Colab):\n",
        "Go to : https://developer.nvidia.com/rdp/cudnn-archive and download cudnn v8.1.1 archive from nvidia website.\n",
        "\n",
        "Selct _Download CuDNN v8.1.1 for CUDA 11.0, 11.1 and 11.2_.\n",
        "\n",
        "Download `cuDNN Library for Linux (x86_64)`. You should have a file called: `cudnn-11.2-linux-x64-v8.1.1.33.tgz`. Then upload it under /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyt7Mtij5AFz",
        "outputId": "9acd26b3-e32e-44a5-b951-198cf6f96023"
      },
      "outputs": [],
      "source": [
        "# in addition to this download and upload to the google colab the cudnn-11.2-linux-x64-v8.1.1.33.tgz file\n",
        "if os.environ[\"GOOGLE_COLAB\"]==\"1\":\n",
        "  from google.colab import files\n",
        "\n",
        "  # Upload \"cudnn-11.2-linux-x64-v8.1.1.33.tgz\" file \n",
        "  uploaded = files.upload()\n",
        "  !tar -xvf cudnn-11.2-linux-x64-v8.1.1.33.tgz\n",
        "  os.environ[\"LD_LIBRARY_PATH\"] = (\n",
        "  \"/usr/local/cuda-11.2/targets/x86_64-linux/lib:\"\n",
        "  \"/usr/local/lib/python3.11/dist-packages/nvidia/cufft/lib:\"\n",
        "  \"/content/cuda/lib64:\"\n",
        "  + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Cloning the stm32ai-modelzoo-services repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFBa0MB26boA",
        "outputId": "35ccf0f1-e586-47c0-aeea-a286b5bce23f"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/STMicroelectronics/stm32ai-modelzoo-services.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJUip3GB67e3"
      },
      "source": [
        "Or, you can upload a lighter version of STM32 model zoo by following these steps:\n",
        "- On your local PC clone STM32AI model zoo git using the following command:\n",
        "```\n",
        "git clone https://github.com/STMicroelectronics/stm32ai-modelzoo-services.git\n",
        "```\n",
        "- Delete the .git directory.\n",
        "\n",
        "- For image classification use-case, you can keep only the folders 'image_classification' and 'common', as well as the file 'requirements.txt', then delete the rest.\n",
        "\n",
        "- Zip the repository as stm32ai-modelzoo-services.zip, and upload **stm32-modelzoo-services.zip** in your workspace.\n",
        "\n",
        "- Then uncomment and run the cell below to unzip the folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCixcLxV7zr3"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('stm32ai-modelzoo-services.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfwzgXd5ef6f"
      },
      "source": [
        "### 1.2 Installing the requirements \n",
        "Installing the requried python libraries and dependecies using `pip install` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Uh7ADKeh8C",
        "outputId": "df12aaa5-c020-4d4f-cf20-92833bfda3b1"
      },
      "outputs": [],
      "source": [
        "if os.environ[\"GOOGLE_COLAB\"]==\"1\":\n",
        "  !python3.10 -m venv st_zoo #create a virtual environment\n",
        "  # install the requirements in the virtual environment\n",
        "  !st_zoo/bin/pip install -r stm32ai-modelzoo-services/requirements.txt\n",
        "  !st_zoo/bin/pip install matplotlib_inline IPython\n",
        "else:\n",
        "  !pip install -r stm32ai-modelzoo-services/requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpPHPEgW-brw"
      },
      "source": [
        "Next, run the following command to install the required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFXdwWJHBin-"
      },
      "source": [
        "<div id=\"config\">\n",
        "    <h2>2. Configure environment variables to access STM32Cube.AI Developer Cloud Services</h2>\n",
        "</div>\n",
        "Set environment variables with your credentials to acces STM32Cube.AI Developer Cloud Services.\n",
        "\n",
        "If you don't have an account yet go to: https://stedgeai-dc.st.com/home and click on sign in to create an account.\n",
        "\n",
        "Then set the environment variables below with your credentials.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-TXBTDpB6WT",
        "outputId": "fb803261-ce7c-47a5-b9f2-235e05e24eec"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ['stmai_username'] = 'user.name@example.com'\n",
        "print('Enter you password')\n",
        "password = getpass.getpass()\n",
        "os.environ['stmai_password'] = password"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8eeXs6h9S6s"
      },
      "source": [
        "<div id=\"upload\">\n",
        "    <h2>3. Upload the dataset</h2>\n",
        "</div>\n",
        "The dataset can be uploaded as a zip archive named **dataset.zip** under the directory 'workspace/stm32ai-modelzoo-services/image_classification/datasets'.\n",
        "\n",
        "The zip file shall contain a directory named \"dataset\" with one sub-directory per category, with images inside as below:\n",
        "\n",
        "```bash\n",
        "dataset_root_directory/\n",
        "   class_a/\n",
        "      a_image_1.jpg\n",
        "      a_image_2.jpg\n",
        "   class_b/\n",
        "      b_image_1.jpg\n",
        "      b_image_2.jpg\n",
        "```\n",
        "Other dataset formats are not supported. The only exceptions are the Cifar10/Cifar100 datasets. For these datasets, the official format in batches is supported.\n",
        "\n",
        "The split between training and validation sets is done automatically by the scripts. However, it is also possible to upload specific training, validation, and test sets by defining specific paths in the user_config.yaml file.\n",
        "\n",
        "In this tutorial we are going to use the flower dataset that can be downloaded directly from tensorflow repository: https://www.tensorflow.org/datasets/catalog/tf_flowers (Creative Commons By-Attribution License 2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip04ofreCrYC",
        "outputId": "de5542a6-871d-4b3e-8295-12d884cf599a"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'tf_flowers' #@param [\"custom\", \"tf_flowers\"]\n",
        "%cd stm32ai-modelzoo-services/image_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "O9Zv5TFhBz6N",
        "outputId": "eb7c98a9-7712-475d-80e4-9fed7cd51ced"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "def download_file(url, save_path):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        # Save the file in chunks\n",
        "        with open(save_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        print(f\"File downloaded successfully: {save_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Failed to download file. HTTP Status Code: {response.status_code}\")\n",
        "        return False\n",
        "\n",
        "def extract_tgz(file_path, extract_path=\".\"):\n",
        "    \"\"\"\n",
        "    Extracts a .tgz or .tar.gz file to the specified directory.\n",
        "    \n",
        "    Args:\n",
        "        file_path (str): Path to the .tgz or .tar.gz file.\n",
        "        extract_path (str): Directory where the contents should be extracted. Defaults to the current directory.\n",
        "    \"\"\"\n",
        "    if tarfile.is_tarfile(file_path):\n",
        "        with tarfile.open(file_path, \"r:gz\") as tar:\n",
        "            tar.extractall(path=extract_path)\n",
        "            print(f\"Extracted '{file_path}' to '{extract_path}'\")\n",
        "    else:\n",
        "        print(f\"'{file_path}' is not a valid .tgz or .tar.gz file.\")\n",
        "\n",
        "\n",
        "# Define the path to the dataset directory\n",
        "if dataset_name == 'tf_flowers':\n",
        "    dataset_path = 'datasets/flower_photos'\n",
        "    url = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "    if download_file(url, dataset_path+'.tgz'):\n",
        "        extract_tgz(dataset_path+'.tgz', extract_path='./datasets/')\n",
        "else:\n",
        "    path = 'datasets/dataset'\n",
        "    with zipfile.ZipFile('datasets/dataset.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('datasets')\n",
        "\n",
        "# Get the list of class names\n",
        "class_names = sorted([name for name in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, name))])\n",
        "num_classes = len(class_names)\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Introducing samples from each class...\")\n",
        "\n",
        "# Print a photo from each class\n",
        "fig, axs = plt.subplots(1, num_classes, figsize=(4*num_classes, 4))\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    image_files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f)) and f.endswith('.jpg')]\n",
        "    if len(image_files) == 0:\n",
        "        img = np.zeros((224, 224, 3))\n",
        "    else:\n",
        "        img_path = os.path.join(class_path, random.choice(image_files))\n",
        "        img = mpimg.imread(img_path)\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].set_title(class_name)\n",
        "    axs[i].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNCJANEqix-W"
      },
      "source": [
        "<div id=\"training\">\n",
        "    <h2>4. Training and Benchmarking the Model</h2>\n",
        "</div>\n",
        "\n",
        "The STM32 model zoo is an invaluable resource that provides a wide range of use cases, including image classification, object detection, audio event detection, hand posture, and human activity recognition. The model zoo offers various services, including training, evaluation, prediction, deployment, quantization, benchmarking, and chained services. These services, such as chain_tbqeb, chain_tqe, chain_eqe, chain_qb, chain_eqeb, and chain_qd, are thoroughly explained in their respective readmes.\n",
        "\n",
        "In this section, we will demonstrate how to train, quantize, evaluate, and benchmark a classification model using the chain_tbqeb service. We will use the MobileNet v2 0.35 model from the model zoo as an example, but you can also use your own custom model. To accomplish this, we will use the `user_config.yaml` file as a configuration file to specify the service and the set of configuration parameters, such as the model, dataset, number of epochs, and preprocessing parameters. Please feel free to review and adjust the training parameters as needed.\n",
        "\n",
        "For a custom dataset, in the dataset section, modify:\n",
        "*   the name and class_names accordingly.\n",
        "*   training path: `training_path: ../datasets/dataset`\n",
        "\n",
        "Then, you can tune the other parameters and save the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yodEvVHgEG2k",
        "outputId": "6c87b7c8-13c3-4a09-8320-c7a56dd8bc0a"
      },
      "outputs": [],
      "source": [
        "if os.environ[\"GOOGLE_COLAB\"]=='1':\n",
        "  !../../st_zoo/bin/python stm32ai_main.py\n",
        "else:\n",
        "  %run stm32ai_main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYcsLaTSGi7J"
      },
      "source": [
        "<div id=\"results\">\n",
        "    <h2>5. Results</h2>\n",
        "</div>\n",
        "The trained and quantized models, along with any artifacts, plots, and figures related to the experiments, can be found in the 'workspace/stm32ai-modelzoo-services/image_classification/src/experiments_outputs' directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "P_P-e9nc6jdl",
        "outputId": "2668e022-89c6-4433-f798-48286f04fee4"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "os.chdir('./src')\n",
        "shutil.make_archive('experiments_outputs', 'zip', 'experiments_outputs')\n",
        "\n",
        "# If running in Google colab following code will download the generated experiments_outputs folder.\n",
        "if os.environ[\"GOOGLE_COLAB\"]==\"1\":\n",
        "  from google.colab import files\n",
        "\n",
        "  # Download a specific file\n",
        "  files.download('experiments_outputs.zip')  # Replace 'filename.ext' with the name of your file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_YmRxWlbLTZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "modelzoo_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
